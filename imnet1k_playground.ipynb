{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e768ad21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[extreme] selected lowest 32 and highest 32 samples per split\n",
      "Group lowest32: members=32 | heldout=32\n",
      "Group highest32: members=32 | heldout=32\n",
      "\n",
      "=== Group lowest32 ===\n",
      "[members/train] batch: imgs=(32, 3, 256, 256), dtype=torch.float32, labs=(32,), min=-1.000, max=1.000\n",
      "[members/train] label counts: 00005:1, 00006:1, 00080:1, 00086:1, 00111:2, 00126:1, 00149:1, 00236:1, 00266:1, 00274:1, 00350:1, 00353:1, 00478:1, 00482:1, 00508:1, 00601:1, 00631:1, 00653:2, 00712:1, 00811:1, 00812:1, 00844:1, 00885:1, 00910:1, 00940:1, 00951:2, 00954:1, 00985:1, 00999:1\n",
      "[members/train] saved preview to: members_preview_lowest32.png\n",
      "[heldout/val] batch: imgs=(32, 3, 256, 256), dtype=torch.float32, labs=(32,), min=-1.000, max=1.000\n",
      "[heldout/val] label counts: 00001:2, 00004:3, 00005:1, 00107:1, 00228:1, 00258:1, 00260:1, 00296:2, 00314:1, 00358:1, 00362:1, 00369:1, 00374:2, 00419:1, 00440:1, 00504:1, 00584:1, 00629:1, 00666:1, 00680:1, 00752:1, 00906:1, 00940:1, 00951:1, 00952:1, 00965:1, 00980:1\n",
      "[heldout/val] saved preview to: heldout_preview_lowest32.png\n",
      "\n",
      "=== Group highest32 ===\n",
      "[members/train] batch: imgs=(32, 3, 256, 256), dtype=torch.float32, labs=(32,), min=-1.000, max=1.000\n",
      "[members/train] label counts: 00055:1, 00115:1, 00123:1, 00153:1, 00163:1, 00202:2, 00411:1, 00443:1, 00490:1, 00533:1, 00536:1, 00618:1, 00632:1, 00655:1, 00674:1, 00679:1, 00709:1, 00727:2, 00743:1, 00765:1, 00774:2, 00811:1, 00828:1, 00842:1, 00848:1, 00857:1, 00955:3\n",
      "[members/train] saved preview to: members_preview_highest32.png\n",
      "[heldout/val] batch: imgs=(32, 3, 256, 256), dtype=torch.float32, labs=(32,), min=-1.000, max=1.000\n",
      "[heldout/val] label counts: 00166:1, 00177:1, 00195:1, 00308:1, 00340:1, 00363:1, 00397:2, 00414:1, 00453:1, 00490:2, 00497:1, 00512:1, 00523:1, 00584:1, 00727:3, 00781:1, 00791:1, 00796:1, 00811:1, 00824:1, 00839:1, 00891:1, 00904:2, 00929:1, 00955:3\n",
      "[heldout/val] saved preview to: heldout_preview_highest32.png\n"
     ]
    }
   ],
   "source": [
    "from attack_by_group1 import load_pullback_npz, build_groups_from_npz, build_transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pullback_npz = '/home/ethanrao/MIA_LDM/ldm4imagenet/runs/ldm_imnet256/imnetv1_10k_pullback.npz'\n",
    "data_root = '/data/mingxing/IMNET100K/'\n",
    "\n",
    "tf = build_transforms(256)\n",
    "train_full = ImageFolder(os.path.join(data_root, \"train\"), transform=tf)\n",
    "val_full   = ImageFolder(os.path.join(data_root, \"val\"),   transform=tf)\n",
    "\n",
    "# undo your Normalize([0.5]*3, [0.5]*3)\n",
    "def _denorm(imgs: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.clamp(imgs * 0.5 + 0.5, 0.0, 1.0)\n",
    "\n",
    "def preview_batch(loader, title, idx_to_class, nrow=8, save_path=None):\n",
    "    imgs, labs = next(iter(loader))            # grab one batch\n",
    "    print(f\"[{title}] batch: imgs={tuple(imgs.shape)}, dtype={imgs.dtype}, \"\n",
    "          f\"labs={tuple(labs.shape)}, min={imgs.min().item():.3f}, max={imgs.max().item():.3f}\")\n",
    "\n",
    "    # quick histogram of labels in this batch\n",
    "    uniq, cnts = np.unique(labs.numpy(), return_counts=True)\n",
    "    hist_str = \", \".join([f\"{idx_to_class[int(u)]}:{int(c)}\" for u, c in zip(uniq, cnts)])\n",
    "    print(f\"[{title}] label counts: {hist_str}\")\n",
    "\n",
    "    # denormalize [+ visualize]\n",
    "    imgs_dn = _denorm(imgs)\n",
    "    grid = make_grid(imgs_dn, nrow=nrow, padding=2)  # CHW\n",
    "    grid_np = grid.permute(1, 2, 0).numpy()          # HWC for matplotlib\n",
    "\n",
    "    rows = (imgs.size(0) + nrow - 1) // nrow\n",
    "    plt.figure(figsize=(nrow * 1.8, rows * 1.8))\n",
    "    plt.imshow(grid_np)\n",
    "    plt.title(f\"{title} â€” batch_size={imgs.size(0)}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight')\n",
    "        print(f\"[{title}] saved preview to: {save_path}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def build_groups_from_npz(npz_path: str, grouping: str, seed: int = 2025, n_random_groups: int = 4):\n",
    "    d = load_pullback_npz(npz_path)\n",
    "    m_idx, h_idx = d['member_indices'], d['heldout_indices']\n",
    "    m_mv, h_mv = d['member_metric'], d['heldout_metric']\n",
    "\n",
    "    if grouping == 'random':\n",
    "        rng = np.random.RandomState(seed)\n",
    "        # create n_random_groups equal-ish splits\n",
    "        m_perm = rng.permutation(len(m_idx))\n",
    "        h_perm = rng.permutation(len(h_idx))\n",
    "        m_groups = [m_idx[m_perm[i::n_random_groups]] for i in range(n_random_groups)]\n",
    "        h_groups = [h_idx[h_perm[i::n_random_groups]] for i in range(n_random_groups)]\n",
    "        names = [f\"rand{i+1}\" for i in range(n_random_groups)]\n",
    "        print(f\"[random] split into {n_random_groups} groups with seed={seed}\")\n",
    "    else:\n",
    "        union = np.concatenate([m_mv, h_mv], axis=0)\n",
    "        if grouping == 'median':\n",
    "            thr = np.median(union)\n",
    "            names = ['low','high']\n",
    "            m_groups = [m_idx[m_mv <= thr], m_idx[m_mv > thr]]\n",
    "            h_groups = [h_idx[h_mv <= thr], h_idx[h_mv > thr]]\n",
    "            print(f\"[threshold] median={thr:.6f}\")\n",
    "        elif grouping == 'quartiles':\n",
    "            q1, med, q3 = np.percentile(union, [25, 50, 75])\n",
    "            names = ['q1','q2','q3','q4']\n",
    "            m_groups = [\n",
    "                m_idx[m_mv <= q1],\n",
    "                m_idx[(m_mv > q1) & (m_mv <= med)],\n",
    "                m_idx[(m_mv > med) & (m_mv <= q3)],\n",
    "                m_idx[m_mv > q3],\n",
    "            ]\n",
    "            h_groups = [\n",
    "                h_idx[h_mv <= q1],\n",
    "                h_idx[(h_mv > q1) & (h_mv <= med)],\n",
    "                h_idx[(h_mv > med) & (h_mv <= q3)],\n",
    "                h_idx[h_mv > q3],\n",
    "            ]\n",
    "            print(f\"[thresholds] q1={q1:.6f}  med={med:.6f}  q3={q3:.6f}\")\n",
    "        elif grouping == \"extreme\":\n",
    "            k = 32\n",
    "            m_sorted = np.argsort(m_mv)\n",
    "            h_sorted = np.argsort(h_mv)\n",
    "            m_low = m_idx[m_sorted[:k]]\n",
    "            m_high = m_idx[m_sorted[-k:]]\n",
    "            h_low = h_idx[h_sorted[:k]]\n",
    "            h_high = h_idx[h_sorted[-k:]]\n",
    "            names = [f\"lowest{k}\", f\"highest{k}\"]\n",
    "            m_groups = [m_low, m_high]\n",
    "            h_groups = [h_low, h_high]\n",
    "            print(f\"[extreme] selected lowest {k} and highest {k} samples per split\")\n",
    "        else:\n",
    "            raise ValueError(\"grouping must be 'random'|'median'|'quartiles'\")\n",
    "    for n, mg, hg in zip(names, m_groups, h_groups):\n",
    "        print(f\"Group {n:>6}: members={len(mg)} | heldout={len(hg)}\")\n",
    "    return dict(names=names, member_groups=m_groups, held_groups=h_groups)\n",
    "\n",
    "# build class name lookups from the *same* datasets used for each loader\n",
    "idx_to_class_train = {v: k for k, v in train_full.class_to_idx.items()}\n",
    "idx_to_class_val   = {v: k for k, v in val_full.class_to_idx.items()}\n",
    "\n",
    "splits = build_groups_from_npz(pullback_npz, 'extreme', seed=2025, n_random_groups=2)\n",
    "\n",
    "# For each group: build loaders, encode latents, run probe_unet (streaming version)\n",
    "for name, mem_idx, held_idx in zip(splits['names'], splits['member_groups'], splits['held_groups']):\n",
    "    if len(mem_idx) == 0 or len(held_idx) == 0:\n",
    "        print(f\"\\n=== Group {name} (skipped; empty) ===\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n=== Group {name} ===\")\n",
    "    m_loader = DataLoader(Subset(train_full, mem_idx.tolist()),\n",
    "                            batch_size=32, shuffle=False,\n",
    "                            num_workers=8, pin_memory=True)\n",
    "    h_loader = DataLoader(Subset(val_full, held_idx.tolist()),\n",
    "                            batch_size=32, shuffle=False,\n",
    "                            num_workers=8, pin_memory=True)\n",
    "\n",
    "    # preview one batch from each\n",
    "    preview_batch(m_loader, \"members/train\", idx_to_class_train, nrow=8, save_path=f\"members_preview_{name}.png\")\n",
    "    preview_batch(h_loader, \"heldout/val\",   idx_to_class_val,   nrow=8, save_path=f\"heldout_preview_{name}.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e2552a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
